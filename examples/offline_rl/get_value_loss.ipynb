{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project path:  /mnt/share_disk/user/daixingyuan/l5kit\n",
      "['C:\\\\Users\\\\XY\\\\AppData\\\\Local\\\\JetBrains\\\\Toolbox\\\\apps\\\\PyCharm-P\\\\ch-0\\\\221.5080.212\\\\plugins\\\\python\\\\helpers-pro\\\\jupyter_debug', 'C:\\\\Users\\\\XY\\\\AppData\\\\Local\\\\JetBrains\\\\Toolbox\\\\apps\\\\PyCharm-P\\\\ch-0\\\\221.5080.212\\\\plugins\\\\python\\\\helpers\\\\pydev', '/mnt/share_disk/user/daixingyuan/l5kit/examples/offline_rl', '/usr/local/envs/l5kit/lib/python38.zip', '/usr/local/envs/l5kit/lib/python3.8', '/usr/local/envs/l5kit/lib/python3.8/lib-dynload', '', '/mnt/share_disk/user/.local/lib/python3.8/site-packages', '/mnt/share_disk/user/xijinhao/l5kit/l5kit', '/mnt/share_disk/user/changzhuorui/DenseTNT/DenseTNT/src/argoverse_api', '/usr/local/envs/l5kit/lib/python3.8/site-packages', '/mnt/share_disk/user/daixingyuan/l5kit']\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|   16265    |  4039527   | 320124624  |    38735988   |      112.19     |        248.36        |        79.25         |        24.83         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# from pycharm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from tempfile import gettempdir\n",
    "\n",
    "from l5kit.configs import load_config_data\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.dataset import EgoDatasetVectorized\n",
    "from l5kit.planning.vectorized.closed_loop_model import VectorizedUnrollModel\n",
    "from l5kit.planning.vectorized.open_loop_model import VectorizedModel\n",
    "from l5kit.vectorization.vectorizer_builder import build_vectorizer\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# project_path = str(Path(__file__).parents[1])\n",
    "project_path = \"/mnt/share_disk/user/daixingyuan/l5kit\"\n",
    "print(\"project path: \", project_path)\n",
    "sys.path.append(project_path)\n",
    "print(sys.path)\n",
    "\n",
    "# prepare data path and load cfg\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = \"/mnt/share_disk/user/public/l5kit/prediction\"\n",
    "\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "\n",
    "# Home path\n",
    "from pathlib import Path\n",
    "\n",
    "dm = LocalDataManager(None)\n",
    "# get config\n",
    "cfg = load_config_data(str(Path(project_path, \"examples/urban_driver/config.yaml\")))\n",
    "\n",
    "# ===== INIT DATASET\n",
    "dataset_path = dm.require(cfg[\"train_data_loader\"][\"key\"])\n",
    "\n",
    "train_zarr = ChunkedDataset(dataset_path).open()\n",
    "vectorizer = build_vectorizer(cfg, dm)\n",
    "train_dataset = EgoDatasetVectorized(cfg, train_zarr, vectorizer)\n",
    "\n",
    "print(train_zarr)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|     1      |    249     |   22099    |      6228     |       0.01      |        249.00        |        88.75         |        24.90         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/share_disk/user/xijinhao/l5kit/l5kit/l5kit/data/zarr_dataset.py:213: RuntimeWarning: zarr dataset path should end with .zarr (for now). Open will fail for this dataset!\n",
      "  dataset = ChunkedDataset(\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "| Num Scenes | Num Frames | Num Agents | Num TR lights | Total Time (hr) | Avg Frames per Scene | Avg Agents per Frame | Avg Scene Time (sec) | Avg Frame frequency |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n",
      "|     1      |    249     |   22099    |      6228     |       0.01      |        249.00        |        88.75         |        24.90         |        10.00        |\n",
      "+------------+------------+------------+---------------+-----------------+----------------------+----------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(cfg, traffic_signal_scene_id=None):\n",
    "    dm = LocalDataManager(None)\n",
    "    # ===== INIT DATASET\n",
    "    # cfg[\"train_data_loader\"][\"key\"] = \"train.zarr\"\n",
    "    train_zarr = ChunkedDataset(dm.require(cfg[\"train_data_loader\"][\"key\"])).open()\n",
    "\n",
    "    vectorizer = build_vectorizer(cfg, dm)\n",
    "    train_dataset = EgoDatasetVectorized(cfg, train_zarr, vectorizer)\n",
    "\n",
    "    # todo demo for single scene\n",
    "    if traffic_signal_scene_id:\n",
    "        train_dataset = train_dataset.get_scene_dataset(traffic_signal_scene_id)\n",
    "    print(train_dataset)\n",
    "    return train_dataset\n",
    "\n",
    "\n",
    "traffic_signal_scene_id = 13\n",
    "cfg = load_config_data(str(Path(project_path, \"examples/urban_driver/config.yaml\")))\n",
    "\n",
    "train_dataset = load_dataset(cfg, traffic_signal_scene_id)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compute truncated value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([26, 3]), torch.Size([26, 12, 2]))"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size与pred_len可变\n",
    "batch_size = 16\n",
    "pred_len = 10  # prediction horizon\n",
    "\n",
    "# 假设batch_size为16，前16个输入到网络，输出对应的next_state, action, reward, value\n",
    "# value_target需要滚动计算，所以共需要16 + 10个样本。\n",
    "# 计算过程中，例如，第1个样本的V(s1)，需要计算2:11样本中的reward之和,\n",
    "# 即V(s1) = r2+r3+...+r11\n",
    "sample_trajectory_len = batch_size + pred_len\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    shuffle=False,  # 注意不打乱顺序，采样连续样本，以构建truncated value\n",
    "    batch_size=sample_trajectory_len,\n",
    "    num_workers=1,\n",
    ")\n",
    "tr_it = iter(train_dataloader)\n",
    "data_batch = next(tr_it)\n",
    "\n",
    "data_batch['extent'].shape, data_batch[\"target_positions\"].shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([13.2083, 13.1780, 13.2734, 13.3055, 13.3941, 13.5879, 13.9029, 14.4856,\n",
      "        15.2478, 16.0507, 16.8346, 17.5826, 18.3533, 19.1106, 19.8922, 20.5748]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "from scripts import reward\n",
    "\n",
    "def get_reward_per_batch(frame):\n",
    "    # todo @jinhao 以下几个per_frame相关函数改名，应该是per_batch了\n",
    "    distance_to_center = reward.get_distance_to_centroid_per_frame(frame)\n",
    "    min_distance_to_other = reward.get_distance_to_other_agents_per_frame(frame)\n",
    "    _reward = -distance_to_center + min_distance_to_other\n",
    "    return _reward\n",
    "\n",
    "def get_truncated_value(_data_batch, _top_n_data, _pred_len):\n",
    "    assert _top_n_data + _pred_len <= _data_batch['extent'].shape[0]\n",
    "    truncated_value_batch = []\n",
    "\n",
    "    all_frame_reward = get_reward_per_batch(_data_batch)\n",
    "    for element_ix in range(_top_n_data):\n",
    "        truncated_value = sum(all_frame_reward[element_ix+1:element_ix+_pred_len+1])\n",
    "        truncated_value_batch.append(truncated_value)\n",
    "\n",
    "    truncated_value_batch = torch.stack(truncated_value_batch)\n",
    "\n",
    "    return truncated_value_batch\n",
    "\n",
    "truncated_value_target = get_truncated_value(data_batch, batch_size, pred_len)\n",
    "print(truncated_value_target, truncated_value_target.shape)\n",
    "\n",
    "\n",
    "# todo @jinhao\n",
    "\n",
    "# 设_pred_len=10\n",
    "# 计算过程中，例如，第1个样本的V(s1)，需要计算2:11样本中的reward之和,\n",
    "# 即V(s1) = r2+r3+...+r11\n",
    "# Note: truncated value的计算不需要加上V(s12), 具体见 equation (8)(9) in the UMBRELLA paper\n",
    "# 以及一篇MBOP代码的实现 https://github.com/zhanzxy5/MOPP/blob/3f9f567f7fffe0e20a9402ffc53f452e78c4137e/rl_planning/mbop_agent.py#L143\n",
    "\n",
    "# data_batch_as_state = {k: v[:batch_size] for k, v in data_batch.items()}\n",
    "# action, prediction, reward, value = model(data_batch_as_state)\n",
    "# loss_value = F.mse_loss(value, truncated_value_target)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}